{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nueva agregación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intenamos subir la accuracy del modelo federado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.dataset import load_dataset\n",
    "from RepartoDatos import RepartoDatos\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLFedAvg import MLFedAvg\n",
    "from funciones_aux import *\n",
    "from Metricas import Metrica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARGA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skmultilearn.dataset import load_from_arff\n",
    "\n",
    "filename = 'SLASHDOT-F.arff'\n",
    "q = 22\n",
    "\n",
    "X, y = load_from_arff(\n",
    "    filename,\n",
    "    label_count=q,\n",
    "    label_location='start',\n",
    "    load_sparse=True # depende del conjunto de datos\n",
    ")\n",
    "\n",
    "X_array = X.toarray() \n",
    "y_array = y.toarray()\n",
    "print(X_array.shape)\n",
    "X=pd.DataFrame(X_array)\n",
    "print(y_array.shape)\n",
    "y=pd.DataFrame(y_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Cargar el dataset emotions completo (undivided), del repositorio que tiene la libreria:\n",
    "# #   http://scikit.ml/datasets.html#scikit-multilearn-repository\n",
    "# X_sparse, y_sparse, feature_names, label_names = load_dataset('scene', 'undivided')\n",
    "# X_array = X_sparse.toarray() # Esto nos da un array de numpy \n",
    "# print(X_array.shape)\n",
    "# X=pd.DataFrame(X_array, columns=[str(feature) for feature in feature_names])\n",
    "\n",
    "\n",
    "# label_names_B = [s for s,v in label_names]\n",
    "# label_names_B\n",
    "# y_array = y_sparse.toarray()\n",
    "# print(y_array.shape)\n",
    "# y=pd.DataFrame(y_array, columns=label_names_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO FEDERADO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetros federado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_clientes=4\n",
    "epochs_por_ronda=1 #epochs que ejecuta cada cliente en cada ronda de federado\n",
    "semilla_aleatoria=1\n",
    "reparto_etiquetas=[10,6,4,2]#etiquetas para cada cliente\n",
    "N_rondas_federado=1000\n",
    "agregacion=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(reparto_etiquetas) != N_clientes:\n",
    "    raise ValueError(\"Error: El número de clientes no se corresponde con el reparto de etiquetas\")\n",
    "\n",
    "\n",
    "if sum(reparto_etiquetas) != y.shape[1]:\n",
    "    raise ValueError(\"El número de etiquetas del dataset no se corresponde con el reparto de etiquetas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición de datos y etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos para obtener un conjunto de test global para probar nuestros modelos al finalizar el entrenamiento de aprendizaje federado. Preparamos los datos eliminando ceros y repartiendo dataset y etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=semilla_aleatoria)\n",
    "X_train,y_train=eliminar_ceros([X_train],[y_train])\n",
    "X_test,y_test=eliminar_ceros([X_test],[y_test]) #conjunto de test global, para evaluación final\n",
    "reparto=RepartoDatos(X_train[0],y_train[0])\n",
    "XC_raw,yC_raw=reparto.dividir_dataset(N_clientes,random_state=semilla_aleatoria) #XC es una lista con los X de todos los clientes, igual con y\n",
    "yC_raw_etiquetas=reparto.dividir_etiquetas(yC_raw,reparto_etiquetas,aleatorio=True,random_state=semilla_aleatoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XC_raw son los daset de cada cliente en bruto. yC_raw tiene las instancias de cada cliente (las que corresponden a XC) pero todos los clientes tienen todas las etiquetas. Ahora las dividimos, en orden o aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora eliminamos las filas las cuales sus etiquetas asociadas son todas 0. Estas serían mis listas con los datos finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC,yC=eliminar_ceros(XC_raw,yC_raw_etiquetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruidoC=lista_aleatoria(N_clientes,0,0.5,semilla_aleatoria)\n",
    "XC_ruido=ruido_lista(XC,ruidoC,semilla_aleatoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del modelo CORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un modelo con tantas neuronas de entrada como atributos tienen mis datos, y con las neuronas que le pase en la lista y creamos el objeto métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronas_core=[XC[0].shape[1],100,20] \n",
    "\n",
    "modelo=MLFedAvg(neuronas_core,S=epochs_por_ronda)\n",
    "modelo_core=modelo.model_core()\n",
    "\n",
    "metricas=Metrica()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada elemento es el numero de neuronas de cada capa. El modelo core tendrá tantas capas como elementos la lista (numero de capas=longitud de la lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos de cada cliente en entrenamiento y test. Estos conjuntos son propios de cada cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC_train_ruido,yC_train,XC_test,yC_test=train_test_split_list(XC_ruido,yC,test_size=0.2,random_state=semilla_aleatoria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instancias_cliente_train=cuenta_instancias(XC_train_ruido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instancias_cliente_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento federado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenamiento_federado(N_rondas,modelo_core,umbral_parada=10):\n",
    "\n",
    "    ultimos_accuracy_entrenamiento = []\n",
    "    primeros_accuracy_entrenamiento = []\n",
    "    ultimos_accuracy_validacion = []\n",
    "    primeros_accuracy_validacion = []\n",
    "    ultimos_loss_validacion = []\n",
    "    primeros_loss_validacion = []\n",
    "    early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=False)\n",
    "    N_ronda_stop=N_rondas\n",
    "    medias_stop_loss=[]\n",
    "    medias_stop_accuracy=[]\n",
    "\n",
    "    \n",
    "    for i in range(N_rondas):\n",
    "        print(\"\\n\")\n",
    "        print(\"-----------------------------------------------------------------------------------------\")\n",
    "        print(\"-----------------------------RONDA {}/{} DE APRENDIZAJE FEDERADO-------------------------\".format(i+1,N_rondas))\n",
    "        print(\"-----------------------------------------------------------------------------------------\")\n",
    "\n",
    "        \n",
    "        modelos_clientes=modelo.create_client_model(modelo_core,yC,show_summ=False)\n",
    "            \n",
    "        if i>0:\n",
    "            modelos_clientes=modelo.aplicar_pesos_ultima_capa(modelos_clientes,pesos_ultima_capa)\n",
    "\n",
    "        modelos_compilados=modelo.compilar_modelos(modelos_clientes,lr=0.0008,metrics=['accuracy'],loss=\"binary_crossentropy\")\n",
    "        modelos_entrenados,accuracy_train, accuracy_val, loss_val, early_stopped=modelo.entrenar_modelos(modelos_compilados, \n",
    "                                                                                                  XC_train_ruido,yC_train,callbacks=[early_stopping_monitor],val_split=0.1,draw=False)        \n",
    "        pesos_ultima_capa=modelo.extraer_pesos_ultima_capa(modelos_entrenados)\n",
    "\n",
    "        for nombre_modelo, accuracy_train in accuracy_train.items():\n",
    "            primeros_accuracy_entrenamiento.append((nombre_modelo, accuracy_train[0]))\n",
    "            ultimos_accuracy_entrenamiento.append((nombre_modelo, accuracy_train[-1]))\n",
    "            \n",
    "        for nombre_modelo, accuracy_val in accuracy_val.items():\n",
    "            primeros_accuracy_validacion.append((nombre_modelo, accuracy_val[0]))\n",
    "            ultimos_accuracy_validacion.append((nombre_modelo, accuracy_val[-1]))\n",
    "\n",
    "        for nombre_modelo, loss_val in loss_val.items():\n",
    "            primeros_loss_validacion.append((nombre_modelo, loss_val[0]))\n",
    "            ultimos_loss_validacion.append((nombre_modelo, loss_val[-1]))\n",
    "        \n",
    "        pesos_por_modelo=modelo.extraer_pesos_intermedios(modelos_entrenados)\n",
    "        pesos_agregados=modelo.agregar_pesos(pesos_por_modelo,instancias_cliente_train,reparto_etiquetas,agg=agregacion)\n",
    "        modelo_core_actualizado=modelo.aplicar_pesos_a_modelo(modelo_core,pesos_agregados)\n",
    "        modelo_core=modelo_core_actualizado\n",
    "\n",
    "        ultimos_accuracy_validacion_dic = {}\n",
    "        ultimos_loss_validacion_dic = {}\n",
    "\n",
    "        for cliente, numero in ultimos_accuracy_validacion:\n",
    "            if cliente in ultimos_accuracy_validacion_dic:\n",
    "                ultimos_accuracy_validacion_dic[cliente].append(numero)\n",
    "            else:\n",
    "                ultimos_accuracy_validacion_dic[cliente] = [numero]\n",
    "\n",
    "        for cliente, numero in ultimos_loss_validacion:\n",
    "            if cliente in ultimos_loss_validacion_dic:\n",
    "                ultimos_loss_validacion_dic[cliente].append(numero)\n",
    "            else:\n",
    "                ultimos_loss_validacion_dic[cliente] = [numero]\n",
    "        \n",
    "        deberia_detenerse=False\n",
    "        \n",
    "        '''\n",
    "        for cliente, valores in ultimos_accuracy_validacion_dic.items():\n",
    "            print(valores)\n",
    "            if len(valores) >= umbral_parada:\n",
    "                if valores[-1] > valores[-2]:\n",
    "                    deberia_detenerse=False\n",
    "\n",
    "       \n",
    "          \n",
    "        if deberia_detenerse==True:\n",
    "            for cliente, valores in ultimos_loss_validacion_dic.items():\n",
    "                if len(valores) >= umbral_parada:\n",
    "                    if valores[-1] < valores[-2]: \n",
    "                        deberia_detenerse=False\n",
    "             '''       \n",
    "        todos_los_valores_loss=[]\n",
    "        todos_los_valores_accuracy=[]\n",
    "\n",
    "        for valores_lista in ultimos_loss_validacion_dic.values():\n",
    "            todos_los_valores_loss.extend(valores_lista)\n",
    "\n",
    "        for valores_lista in ultimos_accuracy_validacion_dic.values():\n",
    "            todos_los_valores_accuracy.extend(valores_lista)\n",
    "        \n",
    "\n",
    "        media_loss=np.mean(todos_los_valores_loss)\n",
    "        media_accuracy=np.mean(todos_los_valores_accuracy)\n",
    "\n",
    "        medias_stop_loss.append(media_loss)\n",
    "        medias_stop_accuracy.append(media_accuracy)\n",
    "\n",
    "        if i >= umbral_parada and medias_stop_loss[-1]>medias_stop_loss[-2] and medias_stop_loss[-2]>medias_stop_loss[-3] and medias_stop_accuracy[-1]<medias_stop_accuracy[-2] and medias_stop_accuracy[-2]<medias_stop_accuracy[-3]:\n",
    "            deberia_detenerse=True\n",
    "\n",
    "        print(medias_stop_loss)\n",
    "        print(medias_stop_accuracy)\n",
    "        if deberia_detenerse and i>=umbral_parada:\n",
    "            N_ronda_stop = i\n",
    "            break\n",
    "           \n",
    "\n",
    "\n",
    "    return modelos_entrenados,ultimos_accuracy_entrenamiento,ultimos_accuracy_validacion,primeros_accuracy_entrenamiento,primeros_accuracy_validacion, ultimos_accuracy_validacion_dic,N_ronda_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_entrenados,ultimos_accuracy_entrenamiento,ultimos_accuracy_validacion,primeros_accuracy_entrenamiento,primeros_accuracy_validacion, ultimos_accuracy_validacion_dic,N_ronda_stop=entrenamiento_federado(N_rondas_federado,modelo_core,umbral_parada=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RENDIMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendimiento sobre el conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos ahora el rendimiento de estos modelos entrenados con el conjunto de test global:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos los y_test global de cada cliente, con sus etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yC_test_global=obtener_etiquetas_test_global(yC_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_global_sin_Ceros,yC_test_global_sin_ceros=eliminar_ceros(X_test*N_clientes,yC_test_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST GLOBAL SIN CEROS EN LAS ETIQUETAS\")\n",
    "evaluar_modelos(modelos_entrenados,X_test_global_sin_Ceros,yC_test_global_sin_ceros)\n",
    "print()\n",
    "print()\n",
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST GLOBAL CON CEROS EN LAS ETIQUETAS\")\n",
    "evaluar_modelos(modelos_entrenados,X_test,yC_test_global)\n",
    "print()\n",
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST PROPIO\")\n",
    "evaluar_modelos(modelos_entrenados,XC_test,yC_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dibujar_graficas(ultimos_accuracy_entrenamiento,ultimos_accuracy_validacion,primeros_accuracy_entrenamiento, primeros_accuracy_validacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación rendimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos propios de cada cliente sin federado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada modelo con sus datos sin rondas federadas, con epochs=Numero de rondas*épocas por donda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_sin_federado=MLFedAvg(neuronas_core,S=N_ronda_stop*epochs_por_ronda)\n",
    "modelo_core_sin_federado=modelo_sin_federado.model_core()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor_TD = EarlyStopping(monitor='val_loss', patience=N_ronda_stop, verbose=1,restore_best_weights=False)\n",
    "\n",
    "\n",
    "modelos_clientes_sin_federado=modelo_sin_federado.create_client_model(modelo_core_sin_federado,yC_train,show_summ=False)\n",
    "modelos_compilados_sin_federado=modelo_sin_federado.compilar_modelos(modelos_clientes_sin_federado,lr=0.01,metrics=['accuracy',metricas.JS()],loss=\"binary_crossentropy\")\n",
    "modelos_entrenados_sin_federado,ultimo_accuracy_train, ultimo_accuracy_val,ltimo_val_loss,a=modelo_sin_federado.entrenar_modelos(modelos_compilados_sin_federado, \n",
    "                                                                                                  XC_train_ruido,yC_train,callbacks=[early_stopping_monitor_TD],val_split=0.1,draw=False)        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST GLOBAL SIN CEROS EN LAS ETIQUETAS\")\n",
    "evaluar_modelos(modelos_entrenados_sin_federado,X_test_global_sin_Ceros,yC_test_global_sin_ceros)\n",
    "\n",
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST GLOBAL CON CEROS EN LAS ETIQUETAS\")\n",
    "evaluar_modelos(modelos_entrenados_sin_federado,X_test,yC_test_global)\n",
    "\n",
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST PROPIO\")\n",
    "evaluar_modelos(modelos_entrenados_sin_federado,XC_test,yC_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Único modelo con todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_unico=MLFedAvg(neuronas_core,S=N_rondas_federado*epochs_por_ronda)\n",
    "modelo_core_unico=modelo_unico.model_core()\n",
    "modelo_core_unico.add(Dense(y.shape[1],activation=\"sigmoid\"))\n",
    "modelo_core_unico.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_modelo_unico = EarlyStopping(monitor='val_loss', patience=N_ronda_stop, verbose=1,restore_best_weights=True)\n",
    "\n",
    "modelo_core_unico.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=[\"binary_crossentropy\"], metrics=[\"accuracy\"])\n",
    "\n",
    "historia=modelo_core_unico.fit(X_train[0],y_train[0],epochs=N_rondas_federado*epochs_por_ronda,batch_size=30,callbacks=[early_stopping_modelo_unico],validation_split=0.2)        \n",
    "plt.plot(historia.history[\"accuracy\"], label='train')\n",
    "plt.plot(historia.history[f'val_{\"accuracy\"}'], label='validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESUMEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=========================================================================\")\n",
    "print(\"=========================================================================\")\n",
    "\n",
    "print(\"RESULTADOS PARA {} CLIENTES, EPOCHS={}  ,  ETIQUETAS: {} ,  RUIDO:{} ,  SEMILLA={}, AGREGACION={}\".format(N_clientes,epochs_por_ronda,reparto_etiquetas,np.round(ruidoC,3),semilla_aleatoria,agregacion))\n",
    "print()\n",
    "print(\"MODELOS ENTRENADOS CON SUS DATOS PROPIOS MEDIANTE APRENDIZAJE FEDERADO\")\n",
    "print(\"==========================================================================\")\n",
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST GLOBAL SIN CEROS EN LAS ETIQUETAS\")\n",
    "evaluar_modelos(modelos_entrenados,X_test_global_sin_Ceros,yC_test_global_sin_ceros)\n",
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST GLOBAL CON CEROS EN LAS ETIQUETAS\")\n",
    "evaluar_modelos(modelos_entrenados,X_test,yC_test_global)\n",
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST PROPIO\")\n",
    "evaluar_modelos(modelos_entrenados,XC_test,yC_test)\n",
    "print()\n",
    "print()\n",
    "print(\"MODELOS ENTRENADOS CON SUS DATOS PROPIOS SIN APRENDIZAJE FEDERADO\")\n",
    "print(\"==========================================================================\")\n",
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST GLOBAL SIN CEROS EN LAS ETIQUETAS\")\n",
    "evaluar_modelos(modelos_entrenados_sin_federado,X_test_global_sin_Ceros,yC_test_global_sin_ceros)\n",
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST GLOBAL CON CEROS EN LAS ETIQUETAS\")\n",
    "evaluar_modelos(modelos_entrenados_sin_federado,X_test,yC_test_global)\n",
    "print(\"EVALUACIÓN MODELOS CON CONJUNTO DE TEST PROPIO\")\n",
    "evaluar_modelos(modelos_entrenados_sin_federado,XC_test,yC_test)\n",
    "print()\n",
    "print()\n",
    "print(\"MODELO CENTRAL ÚNICO CON TODOS LOS DATOS\")\n",
    "print(\"=========================================================================\")\n",
    "evalua_modelo_unico(modelo_core_unico,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Aquí iría el código que ejecuta tus celdas de Jupyter\n",
    "\n",
    "# Al final de la ejecución, mostrar una notificación\n",
    "os.system(\"osascript -e 'display notification \\\"Celdas de Jupyter terminadas\\\"'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
